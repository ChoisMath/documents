import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import datetime    
import pytz
import google.generativeai as genai
import openai
import anthropic # Placeholder for Anthropic, actual library is 'anthropic'


# êµ¬ê¸€ ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ë° ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° (app.pyì™€ ë™ì¼)
SERVICE_ACCOUNT_INFO = st.secrets["google_service_account"]
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
credentials = Credentials.from_service_account_info(SERVICE_ACCOUNT_INFO, scopes=SCOPES)
gc = gspread.authorize(credentials)
SHEET_ID = "1Bx4otXnVjpWONjlOMAecK4l-y3CAzxyNmH-O0mcQY0E"  # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ì‹œíŠ¸ IDë¡œ ë§ì¶”ì„¸ìš”
sh = gc.open_by_key(SHEET_ID)

# ë¡œê·¸ì¸/ê¶Œí•œ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
user_role = st.session_state.get("user_role")
user_email = st.session_state.get("user_email")

# --- API Keys (Streamlit secrets) - ê°œì„ ëœ ë¡œë”© ë°©ì‹ ---
# Gemini API Key
GEMINI_API_KEY = None
try:
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œì—ì„œ ì‹œë„
    if "gemini" in st.secrets and "API_KEY" in st.secrets["gemini"]:
        GEMINI_API_KEY = st.secrets["gemini"]["API_KEY"]
    elif "GEMINI_API_KEY" in st.secrets:
        GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except Exception:
    pass  # ì¡°ìš©íˆ ì‹¤íŒ¨

# OpenAI API Key
OPENAI_API_KEY = None
try:
    if "openai" in st.secrets and "API_KEY" in st.secrets["openai"]:
        OPENAI_API_KEY = st.secrets["openai"]["API_KEY"]
    elif "OPENAI_API_KEY" in st.secrets:
        OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    if OPENAI_API_KEY:
        openai.api_key = OPENAI_API_KEY
except Exception:
    pass  # ì¡°ìš©íˆ ì‹¤íŒ¨

# Anthropic API Key
ANTHROPIC_API_KEY = None
try:
    if "anthropic" in st.secrets and "API_KEY" in st.secrets["anthropic"]:
        ANTHROPIC_API_KEY = st.secrets["anthropic"]["API_KEY"]
    elif "ANTHROPIC_API_KEY" in st.secrets:
        ANTHROPIC_API_KEY = st.secrets["ANTHROPIC_API_KEY"]
except Exception:
    pass  # ì¡°ìš©íˆ ì‹¤íŒ¨

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - ëª¨ë¸ ìºì‹±ìš©
if "cached_models" not in st.session_state:
    st.session_state.cached_models = {}

# --- Model Listing Functions with Caching ---
def list_gemini_models():
    # ìºì‹œ í™•ì¸
    if "gemini" in st.session_state.cached_models:
        return st.session_state.cached_models["gemini"]
    
    if not GEMINI_API_KEY:
        return ["Gemini API Key not configured"]
    
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        # Filter for more common/useful models if the list is too long or contains irrelevant ones
        filtered_models = [m for m in models if "gemini-1.5-pro" in m or "gemini-1.5-flash" in m or "gemini-1.0-pro" in m or "gemini-2.0" in m]
        result = filtered_models if filtered_models else models # Fallback to all if filter is too restrictive
        
        # ìºì‹œì— ì €ì¥
        st.session_state.cached_models["gemini"] = result
        return result
    except Exception as e:
        error_msg = f"Gemini ëª¨ë¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
        return [error_msg]

def list_openai_models():
    # ìºì‹œ í™•ì¸
    if "openai" in st.session_state.cached_models:
        return st.session_state.cached_models["openai"]
    
    if not OPENAI_API_KEY:
        return ["OpenAI API Key not configured"]
    
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        models = client.models.list()
        # Revised filter: be less restrictive, initially include all, then sort
        # Common model prefixes: gpt-4, gpt-3.5. Users can visually filter.
        # Ensure model.id is accessed correctly from the model object in the list.
        model_ids = [model.id for model in models.data]
        
        # Prioritize newer models or those containing "gpt-4" or "gpt-3.5"
        priority_keywords = ["gpt-4o", "gpt-4", "gpt-3.5"]
        
        def sort_key(model_id):
            for i, keyword in enumerate(priority_keywords):
                if keyword in model_id:
                    return (i, model_id) # Prioritize by keyword, then alphabetically
            return (len(priority_keywords), model_id) # Others come after, then alphabetically

        sorted_model_ids = sorted(model_ids, key=sort_key)
        
        # ìºì‹œì— ì €ì¥
        st.session_state.cached_models["openai"] = sorted_model_ids
        return sorted_model_ids

    except Exception as e:
        error_msg = f"OpenAI ëª¨ë¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
        return [error_msg]

def list_anthropic_models():
    # ìºì‹œ í™•ì¸
    if "anthropic" in st.session_state.cached_models:
        return st.session_state.cached_models["anthropic"]
    
    if not ANTHROPIC_API_KEY:
        return ["Anthropic API Key not configured"]
    
    # ê¸°ë³¸ ëª¨ë¸ ëª©ë¡ (fallback)
    default_models = [
        "claude-3-opus-20240229",
        "claude-3-5-sonnet-20241022",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307",
        "claude-2.1",
        "claude-2.0",
        "claude-instant-1.2"
    ]
    
    try:
        # Dynamically fetch models as per documentation
        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        models_page = client.models.list() # Returns a SyncPage[ModelInfo]
        
        # Extract model names/IDs from the ModelInfo objects
        model_ids = []
        
        # Try direct iteration first
        try:
            for model_info in models_page:
                if hasattr(model_info, 'id'):
                    model_ids.append(model_info.id)
                elif hasattr(model_info, 'name'):
                    model_ids.append(model_info.name)
        except:
            # If direct iteration fails, try .data attribute
            if hasattr(models_page, 'data'):
                for model_info in models_page.data:
                    if hasattr(model_info, 'id'):
                        model_ids.append(model_info.id)
                    elif hasattr(model_info, 'name'):
                        model_ids.append(model_info.name)

        # Use default list if dynamic fetching fails
        if not model_ids:
            model_ids = default_models
        else:
            # Sort to have newer/more capable models appear first
            model_ids = sorted(model_ids, reverse=True)
        
        # ìºì‹œì— ì €ì¥
        st.session_state.cached_models["anthropic"] = model_ids
        return model_ids

    except Exception as e:
        # Return default models on error
        st.session_state.cached_models["anthropic"] = default_models
        return default_models

# --- Unified LLM Generation Function ---
def generate_llm_text(provider, model_id, system_prompt, user_prompt, temperature, top_k=None, top_p=None):
    try:
        if provider == "Gemini":
            if not GEMINI_API_KEY: return "Gemini API Key not configured."
            genai.configure(api_key=GEMINI_API_KEY)
            model_name_only = model_id.split('/')[-1] # Extract "gemini-1.5-pro-latest" from "models/gemini-1.5-pro-latest"
            model = genai.GenerativeModel(
                model_name_only,
                system_instruction=system_prompt,
                generation_config={"temperature": temperature, "top_k": top_k}
            )
            response = model.generate_content(user_prompt)
            return response.text
        elif provider == "OpenAI":
            if not OPENAI_API_KEY: return "OpenAI API Key not configured."
            client = openai.OpenAI(api_key=OPENAI_API_KEY)
            completion = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                top_p=top_p 
            )
            return completion.choices[0].message.content
        elif provider == "Anthropic":
            if not ANTHROPIC_API_KEY: return "Anthropic API Key not configured."
            client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY) # Corrected instantiation
            response = client.messages.create(
                model=model_id,
                system=system_prompt,
                messages=[{"role": "user", "content": user_prompt}],
                temperature=temperature,
                top_k=top_k,
                top_p=top_p,
                max_tokens=2000 # Anthropic requires max_tokens
            )
            return response.content[0].text
    except Exception as e:
        return f"{provider} API í˜¸ì¶œ ì˜¤ë¥˜: {e}"

# --- ê¸°ë³¸ê°’ ì„¤ì • (ê°œë°œìê°€ ì½”ë“œì—ì„œ ìˆ˜ì •) ---
DEFAULT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê³ ë“±í•™êµ ë‹´ì„êµì‚¬ë¡œì„œ í•™êµìƒí™œê¸°ë¡ë¶€ì˜ 'í–‰ë™íŠ¹ì„± ë° ì¢…í•©ì˜ê²¬'ì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ì‘ì„± ì›ì¹™:**
1. ìˆ˜ì‹œë¡œ ê´€ì°°í•˜ì—¬ ëˆ„ê°€ ê¸°ë¡ëœ í–‰ë™íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì´ì²´ì ìœ¼ë¡œ í•™ìƒì„ ì´í•´í•  ìˆ˜ ìˆëŠ” ì¢…í•©ì˜ê²¬ ì‘ì„±
2. í•™ìƒì˜ ì„±ì¥ ì •ë„, íŠ¹ê¸°ì‚¬í•­, ë°œì „ ê°€ëŠ¥ì„±ì„ êµ¬ì²´ì ì´ê³  ê°ê´€ì ìœ¼ë¡œ ì„œìˆ 
3. í•™ìƒì— ëŒ€í•œ ì¼ì¢…ì˜ ì¶”ì²œì„œ ë˜ëŠ” ì§€ë„ ìë£Œê°€ ë˜ë„ë¡ ì‘ì„±
4. ê° í•™êµìƒí™œê¸°ë¡ë¶€ í•­ëª©ì— ê¸°ë¡ëœ ìë£Œë¥¼ ì¢…í•©í•˜ì—¬ ê· í˜• ìˆê²Œ ê¸°ìˆ 
5. ìš°ìˆ˜í–‰ë™íŠ¹ì„±ë°œë‹¬ì‚¬í•­ ì˜ˆì‹œë¡œ ë¶€í„° ë¬¸ìì˜ êµ¬ì¡°ì™€ ìŠ¤íƒ€ì¼ í˜•íƒœë¥¼ ë¶„ì„í•˜ì—¬ ì‘ì„±. ìš°ìˆ˜í–‰ë™íŠ¹ì„±ë°œë‹¬ì‚¬í•­ì˜ ì‚¬ëŒì´ ì‘ì„±í•œ ìŠ¤íƒ€ì¼ì²˜ëŸ¼ ê¸€ì„ ì‘ì„±

** ìš°ìˆ˜í–‰ë™íŠ¹ì„±ë°œë‹¬ì‚¬í•­ ë¬¸ì¥ ì˜ˆì‹œ: 
    - í˜¼ì ì¢…ì´ì ‘ê¸° í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ë©° ë§¤ì‚¬ì— ì ê·¹ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  ì°¸ì—¬í•˜ëŠ” ìì„¸ê°€ ë‹ë³´ì„. ìƒˆë¡œ ë°”ë€ŒëŠ” í™˜ê²½ì— ë¯¼ê°í•˜ì—¬ ì£¼ë³€ ì¹œêµ¬ë“¤ê³¼ ê´€ê³„ ë§ºëŠ” ì¼ì— ì¡°ê¸ˆ ì–´ë ¤ì›€ì„ ëŠë¼ì§€ë§Œ ëŠì„ì—†ì´ ìì‹ ì„ ì„±ì°°í•˜ë©° ë‚˜ì•„ì§€ë ¤ëŠ” ëª¨ìŠµì„ ë³´ì„. ë¹„êµì  í•™ì—…ì„±ì·¨ë„ëŠ” ë‚®ìœ¼ë‚˜ ê¸ì •ì ì´ê³  ì ê·¹ì ì¸ ìƒí™œíƒœë„ë¡œ ì¸í•˜ì—¬ ì§„ë¡œì— ëŒ€í•œ ì§„ì§€í•œ ìê¸°ì„±ì°°ê³¼ íƒìƒ‰ì„ í†µí•´ ë¶„ëª…í•˜ê³  êµ¬ì²´ì ì¸ ë°©í–¥ì„ ì •í•˜ì—¬ ê¾¸ì¤€í•˜ê²Œ ë…¸ë ¥í•œë‹¤ë©´ ë¬´ì—‡ì´ë“ ì§€ ë°œì „ê°€ëŠ¥ì„±ì´ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë¨.
    - ë‹¤ì •í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë©´ì´ ìˆì–´ ì‚¬êµì„±ì´ ì¢‹ìœ¼ë©° ìê¸° ë°©ì‹ëŒ€ë¡œ ì¼í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ë‚˜ ë¹„êµì  ì˜ì§€ë ¥ì´ ì•½í•˜ì—¬ ì¶”ì§„ë ¥ì´ ë–¨ì–´ì§. ìŠ¤ìŠ¤ë¡œ ê³µë¶€í•˜ëŠ” ë°©ë²•ì„ í„°ë“í•˜ê³  ìì‹ ì´ ì„¸ìš´ í•™ìŠµê³„íšì— ë”°ë¼ ìê¸°ì£¼ë„ì ìœ¼ë¡œ ì—´ì‹¬íˆ ê³µë¶€í•˜ê³  ìˆì–´ ë°œì „ê°€ëŠ¥ì„±ì´ ì—¿ë³´ì„. ìŒì•…ì„ ì¢‹ì•„í•˜ê³  ë…¸ë˜ ë¶€ë¥´ëŠ”ë°ë„ ì¬ëŠ¥ì´ ìˆìŒ. ì¹œêµ¬ë“¤ì„ ëŒ€í•  ë•Œ í•­ìƒ ì¹œì ˆí•˜ê³  ë‹¤ì •í•˜ê²Œ ëŒ€í•¨ìœ¼ë¡œì¨ ìƒëŒ€ë°©ì„ ë°°ë ¤í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ë§ˆìŒì„ ì‹¤ì²œí•¨. ë‚¯ì„  ì‚¬ëŒì—ê²Œ ì„ ëœ» ì˜ ë‹¤ê°€ì„œì§€ ëª»í•˜ì§€ë§Œ í•œë²ˆ ì‚¬ê·€ë©´ ì§€ì†ì ìœ¼ë¡œ ì¢‹ì€ ì¹œêµ¬ê´€ê³„ë¥¼ ì˜ ìœ ì§€í•¨.
    - ì‹¬ì„±ì´ ë°”ë¥´ê³  ì˜¨ìˆœí•˜ì—¬ ëŒ€ì¸ê´€ê³„ì—ì„œ ë‹¤ì†Œ ìˆ˜ë™ì ì´ê³  ìˆœì‘ì ì¸ í¸ì´ë©° ë§¤ìš° ì‹ ì¤‘í•˜ê³  ì¡°ì‹¬ìŠ¤ëŸ¬ìš°ë©° ë¹„êµì  ì†Œì‹¬í•œ ì„±ê²©ì„. ì˜ˆì˜ê°€ ë°”ë¥´ê³  ì£¼ë³€ ì¹œêµ¬ë“¤ê³¼ ì‚¬ì´ê°€ ë§¤ìš° ì›ë§Œí•˜ì—¬ ëˆ„ê°€ì™€ë„ ì˜ ì§€ëƒ„. êµë‚´ ì™¸ ê³µë™ë„ë•ê³¼ ê·œì¹™ì„ ì˜ ì§€í‚¤ê³  ë‚¨ì—ê²Œ í”¼í•´ë¥¼ ì£¼ëŠ” ì¼ì´ ì—†ë„ë¡ í•­ìƒ ë…¸ë ¥í•¨. í•™ì—…ì— í¥ë¯¸ë¥¼ ëŠë¼ê³  ìˆìœ¼ë¯€ë¡œ ê¾¸ì¤€íˆ ë…¸ë ¥í•œë‹¤ë©´ ì¢‹ì€ ì„±ì·¨ë¥¼ ì´ë£° ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë¨.
    - ë‹¤ì •ë‹¤ê°í•˜ê³  ë‹¤ë¥¸ ì‚¬ëŒë“¤ê³¼ ê´€ê³„ ë§ºëŠ” ê²ƒì„ ì¢‹ì•„í•˜ì§€ë§Œ ë¹„êµì  ìê¸°ì¤‘ì‹¬ì ìœ¼ë¡œ ìƒê°í•˜ì—¬ íŒë‹¨í•˜ëŠ” ê²½í–¥ì´ ìˆìŒ. ê³µë¶€ì˜ í•„ìš”ì„±ì€ ëŠë¼ê³  ìˆìœ¼ë‚˜ ê¸°ì´ˆí•™ë ¥ì´ ë¶€ì¡±í•˜ê³  ì§‘ì¤‘ë ¥ê³¼ ì˜ì§€ë ¥ì´ ì•½í•˜ì—¬ í•™ì—…ì„±ì·¨ë„ê°€ ë‹¤ì†Œ ë‚®ìŒ. ìš”ë¦¬ì— ëŒ€í•œ ê´€ì‹¬ì„ ê°€ì§€ê³  ì—¬ëŸ¬ ê°€ì§€ ì²´í—˜í™œë™ì„ í†µí•´ ì§„ë¡œë¥¼ ëª¨ìƒ‰í•˜ê³  ìˆì–´ ìì‹ ì˜ ë…¸ë ¥ì´ ë”í•´ì§„ë‹¤ë©´ ë°œì „ê°€ëŠ¥ì„±ì´ ìˆì„ ê²ƒìœ¼ë¡œ ë³´ì„. ì²´ìœ¡ì— ëŒ€í•œ í¥ë¯¸ê°€ ë§ì•„ í”¼êµ¬ë¥¼ ì˜í•˜ë©° ìŠ¹ë¶€ìš•ë„ ê°•í•˜ì—¬ í•™ê¸‰ëŒ€í•­ ë¦¬ê·¸ì „ì—ì„œ ì‹¤ë ¥ì„ ë°œíœ˜í•¨.
    - ë§¤ì‚¬ì— ê¸ì •ì ì´ê³  ì¹¨ì°©í•˜ë©° ë§ˆìŒì˜ ë³€í™”ê°€ ì ì€ ì¥ì ì„ ê°€ì§„ í•™ìƒìœ¼ë¡œ ì¹œêµ¬ë“¤ì—ê²Œ ë§¤ìš° ì˜¨ìˆœí•˜ê³  ìˆ˜ìš©ì ì¸ í¸ì´ë¼ ìê¸°ì£¼ì¥ê³¼ í‘œí˜„ì´ ë‹¤ì†Œ ë¶€ì¡±í•¨. ì–´ë¦°ì´ë“¤ì„ ì¢‹ì•„í•˜ê³  ì•„ì´ë“¤ì˜ ëˆˆë†’ì´ì— ë§ê²Œ ì˜ ë†€ì•„ì£¼ê³  ê°€ë¥´ì¹˜ê¸°ë¥¼ ì¦ê±°ì›Œí•˜ë©° ìœ ì•„êµìœ¡ê³¼ ê´€ë ¨ëœ ì¼ì— ë‚¨ë‹¤ë¥¸ ê´€ì‹¬ê³¼ í¥ë¯¸ê°€ ë§ìŒ. ìì‹ ì˜ ì˜ê²¬ì„ í”¼ë ¥í•˜ê¸° ì „ì— í•­ìƒ ì£¼ë³€ ì—¬ê±´ê³¼ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ í•©ë¦¬ì ì´ê³  ì˜¬ê³§ì€ ìì„¸ë¡œ ì˜ê²¬ì„ ì œì‹œí•˜ëŠ” ë“± ê¸ì •ì ì´ê³  ê³ ìš´ ì‹¬ì„±ì„ ê°€ì§.
    - ì •ì´ ë§ê³  ì˜¨ìˆœí•˜ê³  ì˜¨ìˆœí•˜ë©° íƒ€ì¸ì— ëŒ€í•œ ì´í•´ì‹¬ì´ ë§ì•„ êµìš° ê´€ê³„ê°€ ì›ë§Œí•¨. ìƒëŒ€ë°©ì˜ ë§ì„ ì˜ ê²½ì²­í•˜ê³  ìƒëŒ€ë°©ì˜ ì…ì¥ì—ì„œ ë¨¼ì € ì´í•´í•˜ë ¤ê³  ë…¸ë ¥í•¨. ì¹œêµ¬ë“¤ê³¼ì˜ ê´€ê³„ë¥¼ ì£¼ë„í•˜ì§€ëŠ” ëª»í•˜ì§€ë§Œ ê°™ì´ ì–´ìš¸ë¦¬ê¸°ë¥¼ ì¢‹ì•„í•˜ë©° ì¦ê²ê²Œ ì˜ ì§€ë‚´ëŠ” í¸ì„. ìˆ˜ì—…íƒœë„ê°€ ì¢‹ê³  ì„±ì‹¤í•˜ê²Œ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ëŠ” í¸ì´ì§€ë§Œ, ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œ ëª©í‘œë¥¼ ì„¤ì •í•˜ê³  ì‹¤ì²œì´ ë’·ë°›ì¹¨ ëœë‹¤ë©´ ë”ìš± ì§„ì „ëœ í•™ìŠµ ì„±ê³¼ê°€ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë¨. ì§„ë¡œì— ëŒ€í•œ ë³´ë‹¤ êµ¬ì²´ì ì¸ íƒìƒ‰ì„ í†µí•´ ê´€ë ¨ëœ ì •ë³´ì™€ ì§€ì‹ì„ íšë“í•˜ê³  êµ¬ì²´ì ì¸ ì‹¤ì²œ ê³„íšê³¼ ì§€ì†ì ì¸ ë…¸ë ¥ì´ í•„ìš”í•¨.
    - ë°ê³  ê¸ì •ì ì¸ ì‚¬ê³ ë°©ì‹ì„ ê°€ì§€ê³  ìˆì–´ ì‚¬êµì ì´ë©° êµìš°ê´€ê³„ê°€ ì›ë§Œí•¨. ì¹œêµ¬ì˜ ê³ ë¯¼ì‚¬í•­ì„ ì˜ ë“¤ì–´ì£¼ê³  ê³µê°í•˜ë©´ì„œ ê²©ë ¤í•˜ê³  ì±™ê²¨ì¤Œ. í•™ì—…ì— ëŒ€í•œ ìš•ì‹¬ì€ ë‹¤ì†Œ ë¯¸í¡í•˜ì§€ë§Œ ì„±ì‹¤í•˜ê²Œ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ë©° ìì‹ ê³¼ ìƒê°ì„ ìŠ¤ìŠ¤ëŸ¼ì—†ì´ ì˜ í‘œí˜„í•¨. ì¶¤ì— ëŒ€í•œ ì—´ì •ì´ ë„˜ì¹˜ê³  ê¾¸ì¤€íˆ í˜¸í¡ì„ ë§ì¶”ë©´ì„œ ë…¸ë ¥í•˜ëŠ” ëª¨ìŠµì„ ë³´ì´ë©°, ë°˜ê°€ ë°œí‘œíšŒì—ì„œ ì£¼ë„ì ìœ¼ë¡œ ì•ˆë¬´ë¥¼ ì§¬. êµë‚´ í”¼êµ¬ë¦¬ê·¸ì „ì— ì°¸ê°€í•˜ì—¬ ê³µê²©ì„ ì£¼ë„ì ìœ¼ë¡œ ì´ëŒì–´ í•™ê¸‰ì´ ì¢‹ì€ ì„±ì ì„ ì˜¬ë¦¬ëŠ” ë° í¬ê²Œ ê¸°ì—¬í•¨ì€ ë¬¼ë¡  íŒ€ì›ë“¤ì„ ë…ë ¤í•˜ë©´ì„œ ì—´ì •ì ì¸ ëª¨ìŠµìœ¼ë¡œ ì ê·¹ ì°¸ì—¬í•¨.

**ë¬¸ì¥ ìŠ¤íƒ€ì¼ ë° ì–´ë¯¸ í˜•íƒœ:**
1. ì–´ë¯¸ í˜•íƒœ: ë°˜ë“œì‹œ ëª…ì‚¬í˜• ì–´ë¯¸('-í•¨', '-ìŒ', '-ë¨', '-ì„')ë¡œ ì¢…ê²°
   - ì˜¬ë°”ë¥¸ ì˜ˆ: '~ì„ ë³´ì„', '~ì´ ë›°ì–´ë‚¨', '~ì„ ì‹¤ì²œí•¨', '~ì— ê´€ì‹¬ì´ ë§ìŒ', '~ì„ ë„ëª¨í•¨'
   - ì˜ëª»ëœ ì˜ˆ: '~ì„ ë³´ì¸ë‹¤', '~ì´ ë›°ì–´ë‚˜ë‹¤', '~ì„ ì‹¤ì²œí•œë‹¤'

2. ì„œìˆ  êµ¬ì¡°:
   - [êµ¬ì²´ì  ê´€ì°° ì‚¬ì‹¤] + [í–‰ë™ íŠ¹ì„±] + [í‰ê°€/ì „ë§]
   - [í•™ìŠµ/í™œë™ ìƒí™©] + [ë³´ì¸ íƒœë„/ëŠ¥ë ¥] + [ì„±ì¥/ë°œì „ ê°€ëŠ¥ì„±]
   - [ì„±ê²©/íŠ¹ì„±] + [êµ¬ì²´ì  ì‚¬ë¡€] + [ê¸ì •ì  ì˜í–¥/ê²°ê³¼]

3. ë‚´ìš© í¬í•¨ ì˜ì—­:
   - í•™ì—…ì—­ëŸ‰: ìê¸°ì£¼ë„ì  í•™ìŠµíƒœë„, í•™ì—…ì„±ì·¨ë„, íƒêµ¬ì‹¬, ë¬¸ì œí•´ê²°ë ¥ ë“±
   - ì¸ì„±: ì„±ì‹¤ì„±, ì±…ì„ê°, ì •ì§ì„±, ì˜ˆì˜ë°”ë¦„, ë°°ë ¤ì‹¬ ë“±
   - ì‚¬íšŒì„±: êµìš°ê´€ê³„, ë¦¬ë”ì‹­, í˜‘ë ¥, ì˜ì‚¬ì†Œí†µëŠ¥ë ¥, ê°ˆë“±í•´ê²°ëŠ¥ë ¥ ë“±
   - íŠ¹ê¸°Â·ì ì„±: ì˜ˆì²´ëŠ¥, ì§„ë¡œê´€ë ¨ í™œë™, íŠ¹ë³„í•œ ì¬ëŠ¥ì´ë‚˜ ê´€ì‹¬ë¶„ì•¼ ë“±
   - ë´‰ì‚¬ì •ì‹ : ë‚˜ëˆ”, ë°°ë ¤, ê³µë™ì²´ ì˜ì‹, ì‚¬íšŒì°¸ì—¬ ë“±

4. ì„œìˆ  ë°©ì‹:
   - ê´€ì°° ê°€ëŠ¥í•œ êµ¬ì²´ì  ì‚¬ì‹¤ê³¼ í–‰ë™ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ìˆ 
   - ì •ì„±ì  í‰ê°€ì™€ ì •ëŸ‰ì  ì‚¬ì‹¤ì„ ì¡°í™”ë¡­ê²Œ ê²°í•©
   - ê¸ì •ì  ë³€í™”ì™€ ì„±ì¥ ê³¼ì •ì„ ê°•ì¡°
   - í•™ìƒì˜ ê°œë³„ì  íŠ¹ì„±ê³¼ ì¥ì ì´ ë“œëŸ¬ë‚˜ë„ë¡ ê°œë³„í™”í•˜ì—¬ ì‘ì„±

5. 'ooo í•™ìƒì€'ê³¼ ê°™ì€ ì£¼ì–´ëŠ” ì“°ì§€ ì•Šì„ ê²ƒ. ê¸°ë³¸ì ìœ¼ë¡œ í•´ë‹¹ í•™ìƒì— ëŒ€í•œ ì„¸íŠ¹ì´ë¯€ë¡œ ì“°ì§€ ì•ŠëŠ”ë‹¤.

**íŠ¹ìˆ˜ ìƒí™© ì²˜ë¦¬:**
1. ë¶€ì •ì  í–‰ë™íŠ¹ì„± í¬í•¨ ì‹œ: ë°˜ë“œì‹œ ë³€í™” ê°€ëŠ¥ì„±ê³¼ ê°œì„  ë…¸ë ¥ì„ í•¨ê»˜ ê¸°ìˆ 
2. í•™êµí­ë ¥ ì¡°ì¹˜ì‚¬í•­: ã€Œí•™êµí­ë ¥ì˜ˆë°© ë° ëŒ€ì±…ì— ê´€í•œ ë²•ë¥ ã€ ì œ17ì¡°ì— ë”°ë¥¸ ì¡°ì¹˜ì‚¬í•­ì„ ì •í™•í•œ ì¼ìì™€ í•¨ê»˜ ê¸°ì¬
3. ì§ì ‘ ê´€ì°°ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°: ê·¸ ì‚¬ìœ ë¥¼ ëª…ì‹œí•˜ì—¬ ì…ë ¥

**ê¸°ì¬ ì‹œ ìœ ì˜ì‚¬í•­:**
- 300-340ì ë‚´ì™¸ì˜ ì¶©ë¶„í•œ ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±
- ë‹¨ìˆœí•œ ë‚˜ì—´ì´ ì•„ë‹Œ ì¢…í•©ì ì´ê³  ê· í˜•ì¡íŒ í‰ê°€
- í•™ìƒì˜ ì „ì¸ì  ì„±ì¥ì„ ìœ„í•œ ê±´ì„¤ì  ê´€ì  ìœ ì§€
- ê°ê´€ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ì–´ì¡°"""

DEFAULT_TEMPERATURE = 0.7
DEFAULT_TOP_K = 40 # For Gemini and Anthropic
DEFAULT_TOP_P = 0.9 # For OpenAI and Anthropic (if top_k is not used)

# Helper: í•œê¸€ ì ‘ë¯¸ì‚¬ ì œê±°
def extract_number(value, suffix):
    if value and value.endswith(suffix):
        return value.replace(suffix, "")
    return value

# ------------------- í–‰ë°œìƒì„± ê¸°ëŠ¥ -------------------
st.header("í–‰ë™íŠ¹ì„± ë° ë°œë‹¬ì‚¬í•­")
counseling_allowed_roles = st.session_state.get('board_roles', {}).get("í–‰ë°œìƒì„±", []) # Safer access
if user_role not in counseling_allowed_roles:
    st.info("í–‰ë°œìƒì„± ê¸°ëŠ¥ì€ í—ˆìš©ëœ ì‚¬ìš©ìë§Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„ìš” ë° ì˜¤ë¥˜ ì‹œ ê´€ë¦¬ì(í˜ìŒ¤, complete860127@gmail.com)ì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
else:
    # í–‰ë°œìƒì„± ì‹œíŠ¸ ì—´ê¸°
    try:
        character_ws = sh.worksheet("character")
        # ê¸°ì¡´ ì‹œíŠ¸ì˜ í—¤ë”ë¥¼ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ì—…ë°ì´íŠ¸
        try:
            headers = character_ws.row_values(1)
            expected_headers = ["í•™ë…„", "ë°˜", "ë²ˆí˜¸", "ì´ë¦„", "ë°œë‹¬ì‚¬í•­", "ê¸°ë¡ì‹œê°„", "ì…ë ¥ì"]
            if headers != expected_headers:
                # í—¤ë”ê°€ ë‹¤ë¥¸ ê²½ìš° ìƒˆ ì‹œíŠ¸ë¥¼ ë§Œë“¤ê±°ë‚˜ ê²½ê³ 
                st.warning("ê¸°ì¡´ ì‹œíŠ¸ì˜ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        except:
            pass
    except Exception:
        character_ws = sh.add_worksheet(title="character", rows=1000, cols=10)
        character_ws.append_row(["í•™ë…„", "ë°˜", "ë²ˆí˜¸", "ì´ë¦„", "ë°œë‹¬ì‚¬í•­", "ê¸°ë¡ì‹œê°„", "ì…ë ¥ì"])
    
    # students ì‹œíŠ¸ ì—´ê¸°
    try:
        students_ws = sh.worksheet("students")
    except Exception:
        st.warning("students ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìƒ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        students_ws = None

    # Initialize session state for form fields if not present
    if "llm_dev_text" not in st.session_state:
        st.session_state.llm_dev_text = ""
    
    # students ì‹œíŠ¸ì—ì„œ í•™ìƒ ì´ë¦„ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
    def get_student_name(grade, class_num, student_num):
        if not students_ws:
            return ""
        try:
            all_students = students_ws.get_all_records()
            # í•™ë…„, ë°˜, ë²ˆí˜¸ë¡œ í•™ìƒ ì°¾ê¸°
            for student in all_students:
                if (student.get('í•™ë…„') == grade and 
                    student.get('ë°˜') == class_num and 
                    student.get('ë²ˆí˜¸') == student_num):
                    return student.get('ì´ë¦„', '')
            return ""
        except Exception as e:
            st.error(f"í•™ìƒ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return ""
    
    # í•™ìƒ ì •ë³´ë¡œ ê¸°ì¡´ ë°œë‹¬ì‚¬í•­ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
    def get_existing_development(grade, class_num, student_num, user_email):
        try:
            all_records = character_ws.get_all_records()
            # í•´ë‹¹ í•™ìƒì˜ ê¸°ë¡ ì¤‘ ì…ë ¥ìê°€ ë³¸ì¸ì¸ ê²ƒë§Œ í•„í„°ë§
            student_records = [
                record for record in all_records
                if record.get('í•™ë…„') == grade and 
                   record.get('ë°˜') == class_num and 
                   record.get('ë²ˆí˜¸') == student_num and 
                   record.get('ì…ë ¥ì') == user_email
            ]
            
            if student_records:
                # ê¸°ë¡ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœê·¼ ê²ƒ ë°˜í™˜
                # ê¸°ë¡ì‹œê°„ì´ ë¬¸ìì—´ë¡œ ì €ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ datetimeìœ¼ë¡œ ë³€í™˜ ì‹œë„
                try:
                    sorted_records = sorted(
                        student_records, 
                        key=lambda x: datetime.datetime.strptime(x.get('ê¸°ë¡ì‹œê°„', ''), '%Y-%m-%d %H:%M:%S'),
                        reverse=True
                    )
                    return sorted_records[0].get('ë°œë‹¬ì‚¬í•­', '')
                except:
                    # ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨ì‹œ ì²« ë²ˆì§¸ ê¸°ë¡ ë°˜í™˜
                    return student_records[0].get('ë°œë‹¬ì‚¬í•­', '')
            return ""
        except Exception as e:
            st.error(f"ê¸°ì¡´ ë°œë‹¬ì‚¬í•­ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return ""
    
    import re

    def extract_number(value):
        if value:
            m = re.search(r'\d+', value)
            if m:
                return int(m.group())
        return None

    # --- LLM ê¸°ë°˜ ë°œë‹¬ì‚¬í•­ ìƒì„± ì„¹ì…˜ ---
    st.sidebar.subheader("âœ¨ LLM ê¸°ë°˜ ë°œë‹¬ì‚¬í•­ ìƒì„± ë„ìš°ë¯¸ âœ¨")
    
    # API í‚¤ ìƒíƒœ í‘œì‹œ
    api_status = {
        "Gemini": "âœ… ì„¤ì •ë¨" if GEMINI_API_KEY else "âŒ ë¯¸ì„¤ì •",
        "OpenAI": "âœ… ì„¤ì •ë¨" if OPENAI_API_KEY else "âŒ ë¯¸ì„¤ì •", 
        "Anthropic": "âœ… ì„¤ì •ë¨" if ANTHROPIC_API_KEY else "âŒ ë¯¸ì„¤ì •"
    }
    
    # st.sidebar.caption("API í‚¤ ìƒíƒœ:")
    # for provider, status in api_status.items():
    #     st.sidebar.caption(f"- {provider}: {status}")
    
    # ì´ì „ ì„ íƒëœ ê³µê¸‰ì ì¶”ì 
    if "prev_provider" not in st.session_state:
        st.session_state.prev_provider = None
    
    selected_provider = st.sidebar.selectbox(
        "LLM ê³µê¸‰ì ì„ íƒ",
        ["Gemini", "OpenAI", "Anthropic"],
        index=0, # Default to Gemini
        key="llm_provider"
    )
    
    # ê³µê¸‰ìê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ëª¨ë¸ ëª©ë¡ ë¡œë“œ
    if selected_provider != st.session_state.prev_provider:
        st.session_state.prev_provider = selected_provider
        # ìºì‹œ ë¬´íš¨í™” (ì„ íƒì )
        # if selected_provider.lower() in st.session_state.cached_models:
        #     del st.session_state.cached_models[selected_provider.lower()]
    
    # ëª¨ë¸ ëª©ë¡ ë¡œë“œ (ìºì‹±ë¨)
    with st.spinner(f"{selected_provider} ëª¨ë¸ ëª©ë¡ ë¡œë”© ì¤‘..."):
        if selected_provider == "Gemini":
            models_list = list_gemini_models()
        elif selected_provider == "OpenAI":
            models_list = list_openai_models()
        elif selected_provider == "Anthropic":
            models_list = list_anthropic_models()
    
    # ëª¨ë¸ ì„ íƒ
    if models_list and not any("API Key not configured" in str(m) for m in models_list):
        selected_model = st.sidebar.selectbox(
            f"{selected_provider} ëª¨ë¸ ì„ íƒ",
            models_list,
            key="llm_model_id"
        )
    else:
        st.sidebar.error(f"{selected_provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        selected_model = None

    with st.sidebar.expander("System Prompt (LLM ì§€ì‹œì‚¬í•­)", expanded=False):
        llm_system_prompt = st.text_area(
            "System Prompt (LLM ì§€ì‹œì‚¬í•­)",
            value=st.session_state.get("llm_system_prompt", DEFAULT_SYSTEM_PROMPT),
            key="llm_system_prompt",
            height=200
        )

    llm_temperature = st.sidebar.slider(
        "Temperature (ì°½ì˜ì„±)", 
        min_value=0.0, max_value=1.0, 
        value=st.session_state.get("llm_temperature", DEFAULT_TEMPERATURE), 
        step=0.05, 
        key="llm_temperature"
    )

    llm_top_k = None
    llm_top_p = None

    if selected_provider in ["Gemini", "Anthropic"]:
        llm_top_k = st.sidebar.slider(
            "Top-K (ë‹¤ìŒ ë‹¨ì–´ ì„ íƒ í›„ë³´êµ°)", 
            min_value=1, max_value=100, 
            value=st.session_state.get("llm_top_k", DEFAULT_TOP_K), 
            step=1, 
            key="llm_top_k"
        )
    if selected_provider in ["OpenAI", "Anthropic"]: # Anthropic supports both
        llm_top_p = st.sidebar.slider(
            "Top-P (ë‹¤ìŒ ë‹¨ì–´ ì„ íƒ í™•ë¥  ì„ê³„ê°’)", 
            min_value=0.0, max_value=1.0, 
            value=st.session_state.get("llm_top_p", DEFAULT_TOP_P), 
            step=0.01, 
            key="llm_top_p"
        )

    st.markdown("---") # Separator before the form

    # Form for submitting student data
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        grade_raw = st.selectbox("í•™ë…„", options=["", "1í•™ë…„", "2í•™ë…„", "3í•™ë…„"], key="grade_select")
    with col2:
        class_num_raw = st.selectbox("ë°˜", options=["", "1ë°˜", "2ë°˜", "3ë°˜", "4ë°˜", "5ë°˜", "6ë°˜"], key="class_select")
    with col3:
        student_num_raw = st.selectbox("ë²ˆí˜¸", options=[""] + [f"{i}ë²ˆ" for i in range(1, 31)], key="student_num_select")
    
    # ìˆ«ìë§Œ ì¶”ì¶œ
    grade = extract_number(grade_raw)
    class_num = extract_number(class_num_raw)
    student_num = extract_number(student_num_raw)

    # í•™ë…„, ë°˜, ë²ˆí˜¸ê°€ ëª¨ë‘ ì„ íƒë˜ë©´ í•™ìƒ ì´ë¦„ê³¼ ë°œë‹¬ì‚¬í•­ ìë™ ì¡°íšŒ
    if grade and class_num and student_num:
        # ì„¸ì…˜ ìƒíƒœì— ì´ì „ ì„ íƒ ì •ë³´ ì €ì¥
        current_selection = f"{grade}_{class_num}_{student_num}"
        if "prev_student_selection" not in st.session_state:
            st.session_state.prev_student_selection = ""
        
        # í•™ìƒì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ì¡°íšŒ
        if current_selection != st.session_state.prev_student_selection:
            st.session_state.prev_student_selection = current_selection
            
            # í•™ìƒ ì´ë¦„ ì¡°íšŒ
            student_name = get_student_name(grade, class_num, student_num)
            if student_name:
                st.session_state.student_name = student_name
            else:
                st.session_state.student_name = ""
            
            # ë°œë‹¬ì‚¬í•­ ì¡°íšŒ
            existing_dev = get_existing_development(grade, class_num, student_num, user_email)
            if existing_dev:
                st.session_state.form_development_text = existing_dev
            else:
                st.session_state.form_development_text = ""
    
    # ì´ë¦„ ì…ë ¥ í•„ë“œ - ìë™ìœ¼ë¡œ ì±„ì›Œì§€ê±°ë‚˜ ìˆ˜ë™ ì…ë ¥ ê°€ëŠ¥
    with col4:
        name = st.text_input(
            "ì´ë¦„", 
            value=st.session_state.get("student_name", ""),
            key="name"
        )
    
    # User Promptë¥¼ ë©”ì¸ ì˜ì—­ìœ¼ë¡œ ì´ë™ (ì œëª© ì•„ë˜)
    llm_user_prompt = st.text_area(
        "User Prompt (í•™ìƒ íŠ¹ì„± ìš”ì•½)",
        value=st.session_state.get("llm_user_prompt", ""),
        key="llm_user_prompt",
        placeholder="ì˜ˆ: ê¹€ì² ìˆ˜, 1í•™ë…„. ìˆ˜í•™ì— ì¬ëŠ¥ì´ ìˆìœ¼ë‚˜ ìì‹ ê° ë¶€ì¡±. ì¹œêµ¬ê´€ê³„ ì›ë§Œ. ë¯¸ìˆ  ëŒ€íšŒ ìˆ˜ìƒ.",
        height=100
    )
    
    # LLM ìƒì„± ë²„íŠ¼ (ë©”ì¸ ì˜ì—­ìœ¼ë¡œ ì´ë™)
    col_gen1, col_gen2, col_gen3 = st.columns([1, 3, 1])
    with col_gen3:
        if st.button("ğŸ¤– AI ìƒì„±", key="generate_llm_dev", disabled=not selected_model):
            if not selected_model:
                st.error(f"{selected_provider} API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            elif not llm_user_prompt.strip():
                st.warning("User Promptì— í•™ìƒ íŠ¹ì„±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner(f"{selected_provider} ({selected_model}) ëª¨ë¸ë¡œ ìƒì„± ì¤‘..."):
                    generated_text = generate_llm_text(
                        selected_provider,
                        selected_model,
                        llm_system_prompt,
                        llm_user_prompt,
                        llm_temperature,
                        top_k=llm_top_k if selected_provider in ["Gemini", "Anthropic"] else None,
                        top_p=llm_top_p if selected_provider in ["OpenAI", "Anthropic"] else None
                    )
                    # ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ ë°œë‹¬ì‚¬í•­ í•„ë“œì— ì…ë ¥
                    st.session_state.form_development_text = generated_text
                    st.success("AIê°€ ë°œë‹¬ì‚¬í•­ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
    
    # Use session state to allow updating from LLM generation
    if "form_development_text" not in st.session_state:
        st.session_state.form_development_text = ""
    
    # ë°œë‹¬ì‚¬í•­ ì…ë ¥ í•„ë“œ
    development = st.text_area(
        "ë°œë‹¬ì‚¬í•­: AIê°€ ìƒì„±í•œ ë‚´ìš©ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", 
        value=st.session_state.form_development_text if st.session_state.form_development_text else "ê¸°ë¡ëœ ë‚´ìš©ì´ ì—†ìŒ",
        key="form_development_input",
        height=200
    )
    
    with col_gen1:
        if st.button("ğŸ“¥ ë¶ˆëŸ¬ì˜¤ê¸°", key="load_existing"):
            if grade and class_num and student_num:
                # í•™ìƒ ì´ë¦„ ë‹¤ì‹œ ì¡°íšŒ
                student_name = get_student_name(grade, class_num, student_num)
                if student_name:
                    st.session_state.student_name = student_name
                
                # ë°œë‹¬ì‚¬í•­ ë‹¤ì‹œ ì¡°íšŒ
                existing_dev = get_existing_development(grade, class_num, student_num, user_email)
                if existing_dev:
                    st.session_state.form_development_text = existing_dev
                    st.info("ê¸°ì¡´ ë°œë‹¬ì‚¬í•­ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                else:
                    st.session_state.form_development_text = ""
                    st.info("ì €ì¥ëœ ë°œë‹¬ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.rerun()
            else:
                st.warning("í•™ë…„, ë°˜, ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    # ì €ì¥ ë²„íŠ¼
    if st.button("ğŸ’¾ ì €ì¥", type="primary", use_container_width=True):
        # í¼ ì…ë ¥ê°’ ê°€ì ¸ì˜¤ê¸°
        development_text = st.session_state.get("form_development_input", "")
        final_name = st.session_state.get("student_name", "")  # ì‚¬ìš©ìê°€ ìˆ˜ì •í–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì…ë ¥ í•„ë“œ ê°’ ì‚¬ìš©
        
        # "ê¸°ë¡ëœ ë‚´ìš©ì´ ì—†ìŒ"ì¸ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
        if development_text == "ê¸°ë¡ëœ ë‚´ìš©ì´ ì—†ìŒ":
            development_text = ""
        
        if not grade or not class_num or not student_num:
            st.error("í•™ë…„, ë°˜, ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
        elif not final_name.strip():
            st.error("ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not development_text.strip():
            st.error("ë°œë‹¬ì‚¬í•­ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            # í˜„ì¬ ì‹œê°„ (ì‹œë¶„ì´ˆ í¬í•¨)
            current_time = datetime.datetime.now(pytz.timezone('Asia/Seoul'))
            time_str = current_time.strftime('%Y-%m-%d %H:%M:%S')
            
            # ì…ë ¥ì ì´ë©”ì¼
            input_email = user_email if user_email else "Unknown"
            
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì €ì¥
            character_ws.append_row([grade, class_num, student_num, final_name, development_text, time_str, input_email])
            st.success(f"í–‰ë°œìƒì„± ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ì €ì¥ì‹œê°„: {time_str})")
            
            # Clear the form fields after successful submission
            for k in ["llm_dev_text", "form_development_text", "llm_user_prompt", "prev_student_selection", "student_name"]:
                st.session_state.pop(k, None)
            st.rerun()


